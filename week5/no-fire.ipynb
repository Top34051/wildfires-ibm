{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/Jan_09/'\n",
    "fire = pd.read_csv(path + 'Historical_Wildfire_fill0_new.csv')\n",
    "weather = pd.read_csv(path + 'HistoricalWeather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_weather(w):\n",
    "    w = w.copy()\n",
    "    w = w.rename(columns = {'max()': 'max', 'min()': 'min', 'mean()': 'mean'})\n",
    "    w = w.pivot_table(columns = 'Parameter', \n",
    "                      index = ['Date', 'Region'],\n",
    "                      values = ['min', 'max', 'mean'])\n",
    "    w.reset_index(inplace = True)\n",
    "    w.columns = [col[0] if not(col[1]) else '{1}_{0}'.format(*col) for col in w.columns.values]\n",
    "    return w\n",
    "\n",
    "def combine_data(f, w):\n",
    "    f = f.copy()\n",
    "    w = w.copy()\n",
    "    w = pivot_weather(w)\n",
    "    data = pd.merge(f[['Date', 'Region', 'Estimated_fire_area']], w, on = ['Date', 'Region'])\n",
    "    data['Safe'] = (data['Estimated_fire_area'] == 0).astype(int)\n",
    "    data = data.set_index('Date')\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "def prepare(data, region, lag = 7, period = 15):\n",
    "    data = data.copy()\n",
    "    data = data[data['Region'] == region]\n",
    "    data = data[['Safe', 'Estimated_fire_area', 'SolarRadiation_max', 'SolarRadiation_min', 'SolarRadiation_mean', 'SoilWaterContent_max', 'SoilWaterContent_min', 'SoilWaterContent_mean']]\n",
    "    data['Safe'] = data['Safe'].astype('category')\n",
    "    \n",
    "    for i in range(period):\n",
    "        data[f'Prev_fire_area_{i}'] = data['Estimated_fire_area'].shift(lag+i)\n",
    "    data = data[period+lag:]\n",
    "    data = data.drop(['Estimated_fire_area'], axis = 1)\n",
    "    \n",
    "    data['Month'] = pd.to_datetime(data.index).month\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combine_data(fire, weather)\n",
    "\n",
    "for reg in regions:\n",
    "    df = prepare(data, region = reg)\n",
    "    df.to_csv(f'../data/safe/{reg}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare(data, 'NSW')\n",
    "    \n",
    "X, y = df.drop('no', axis = 1), df['no']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.3, shuffle = True)\n",
    "    \n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 400, 600),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, .1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.50, 1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 10),\n",
    "        'objective': 'binary:logistic'\n",
    "    }\n",
    "    \n",
    "    bst = xgb.train(params, dtrain)\n",
    "    preds = bst.predict(dvalid)\n",
    "    pred_labels = np.rint(preds)\n",
    "    \n",
    "    accuracy = accuracy_score(y_valid, pred_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 18:08:53,110]\u001b[0m A new study created in memory with name: no-name-b6317733-4fe8-422b-a061-093d583846fb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:08:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 18:08:53,400]\u001b[0m Trial 0 finished with value: 0.8442906574394463 and parameters: {'n_estimators': 537, 'max_depth': 12, 'learning_rate': 0.06441369915540854, 'subsample': 0.795484711012629, 'colsample_bytree': 0.5822594284035973, 'gamma': 8}. Best is trial 0 with value: 0.8442906574394463.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:08:53,568]\u001b[0m Trial 1 finished with value: 0.8477508650519031 and parameters: {'n_estimators': 413, 'max_depth': 16, 'learning_rate': 0.0628308054416292, 'subsample': 0.5023372283963035, 'colsample_bytree': 0.8536619768861549, 'gamma': 6}. Best is trial 0 with value: 0.8442906574394463.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:08:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:08:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 18:08:53,858]\u001b[0m Trial 2 finished with value: 0.8350634371395617 and parameters: {'n_estimators': 562, 'max_depth': 19, 'learning_rate': 0.057809938109588566, 'subsample': 0.8338140047167943, 'colsample_bytree': 0.843504998103638, 'gamma': 0}. Best is trial 2 with value: 0.8350634371395617.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:08:54,013]\u001b[0m Trial 3 finished with value: 0.842560553633218 and parameters: {'n_estimators': 530, 'max_depth': 14, 'learning_rate': 0.07238264777356158, 'subsample': 0.7973199169374559, 'colsample_bytree': 0.5007874860241877, 'gamma': 9}. Best is trial 2 with value: 0.8350634371395617.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:08:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:08:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 18:08:54,164]\u001b[0m Trial 4 finished with value: 0.8437139561707035 and parameters: {'n_estimators': 417, 'max_depth': 15, 'learning_rate': 0.08764975219477278, 'subsample': 0.5844297365349467, 'colsample_bytree': 0.675883428224566, 'gamma': 10}. Best is trial 2 with value: 0.8350634371395617.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:08:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 18:08:54,609]\u001b[0m Trial 5 finished with value: 0.8483275663206459 and parameters: {'n_estimators': 566, 'max_depth': 15, 'learning_rate': 0.09102133620203909, 'subsample': 0.8116508670337998, 'colsample_bytree': 0.7318541294458641, 'gamma': 9}. Best is trial 2 with value: 0.8350634371395617.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:08:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 18:08:54,841]\u001b[0m Trial 6 finished with value: 0.825836216839677 and parameters: {'n_estimators': 474, 'max_depth': 16, 'learning_rate': 0.09618539462707716, 'subsample': 0.9692709408388558, 'colsample_bytree': 0.9652105230288367, 'gamma': 0}. Best is trial 6 with value: 0.825836216839677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:08:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 18:08:55,213]\u001b[0m Trial 7 finished with value: 0.8431372549019608 and parameters: {'n_estimators': 512, 'max_depth': 13, 'learning_rate': 0.07717993155987116, 'subsample': 0.968228854411284, 'colsample_bytree': 0.5865087240883982, 'gamma': 5}. Best is trial 6 with value: 0.825836216839677.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:08:55,366]\u001b[0m Trial 8 finished with value: 0.8419838523644751 and parameters: {'n_estimators': 581, 'max_depth': 20, 'learning_rate': 0.05759810962033848, 'subsample': 0.9770794247128916, 'colsample_bytree': 0.5017206090296363, 'gamma': 8}. Best is trial 6 with value: 0.825836216839677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:08:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:08:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 18:08:55,513]\u001b[0m Trial 9 finished with value: 0.8471741637831603 and parameters: {'n_estimators': 407, 'max_depth': 18, 'learning_rate': 0.034795323624327724, 'subsample': 0.8203250034200062, 'colsample_bytree': 0.7572103245376153, 'gamma': 9}. Best is trial 6 with value: 0.825836216839677.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective,n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.825836216839677, params {'n_estimators': 474, 'max_depth': 16, 'learning_rate': 0.09618539462707716, 'subsample': 0.9692709408388558, 'colsample_bytree': 0.9652105230288367, 'gamma': 0}\n"
     ]
    }
   ],
   "source": [
    "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_params['objective'] = 'binary:logistic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:00:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5071606008495954, gamma=3,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.08554437725880452, max_delta_step=0, max_depth=20,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=415, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=0.9671433220891672, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the XGBoost classifier with optimal hyperparameters\n",
    "clf = xgb.XGBClassifier(**best_params)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442367601246106"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_valid)\n",
    "f1_score(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8500999333777481"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "f1_score(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1499.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         235.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1532.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         202.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
